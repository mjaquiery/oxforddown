---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
---

# Network effects of interaction {#chapter-network-effects}
\adjustmtc 

```{r}
source('scripts_and_filters/general_setup.R')
library(adviseR)
library(igraph)
library(BayesFactor)
library(magrittr)

library(gifski)
```

<!-- We may have some modelling to present along these lines. -->

## Models with agents drawn from a distribution



### Can we reproduce the major polarisation/echo chamber effects?

```{r}

starting_weight <- .1
parameters <- data.frame(
  n_agents = 20,
  n_decisions = 500,
  conf = c(T, T, F, F),
  bias_mean = 1,
  bias_sd = 1,
  sensitivity_sd = 1,
  trust_volatility_mean = .05,
  trust_volatility_sd = .01,
  bias_volatility_mean = 0,
  bias_volatility_sd = c(0, .05, 0, .05),
  starting_graph = starting_weight,
  randomSeed = 20201014
)

models <- runSimulations(parameters, cores = nrow(parameters))

for (m in models) {
  networkGraph(
    m, 
    mark.groups = list(
      which(V(m$model$graphs[[1]])$bias <= 0),
      which(V(m$model$graphs[[1]])$bias > 0)
    ), 
    layout = layout_nicely
  ) 
  
  biasGraph(m) %>% print()
  
  weights <- m$model$graphs[[m$parameters$n_decisions]] %>% 
    edge_attr() %>%
    as_tibble() %>%
    mutate(
      `Group name` = factor(if_else(headBias > 0, 'Right', 'Left')), 
      group = factor(paste0(`Group name`, '\n')),
      sameGroup = factor(if_else(
        sign(headBias) == sign(tailBias), 
        'Same group', 
        'Different groups'
      )),
      id = factor(head_of(
        m$model$graphs[[m$parameters$n_decisions]], 
        E(m$model$graphs[[m$parameters$n_decisions]])
      ))
    ) %>%
    group_by(id, group, sameGroup, `Group name`) %>%
    summarise(weight = mean(weight), .groups = 'drop')
  
  ez::ezANOVA(
    data = weights, 
    dv = weight, 
    wid = id, 
    within = sameGroup, 
    between = group,
    type = 2
  ) %>% print()
  
  bf <- weights %>% 
    select(id, `Group name`, weight) %>%
    pivot_wider(
      names_from = `Group name`, 
      values_from = weight,
      values_fn = list
    ) %$%
    ttestBF(Left[[1]], Right[[1]]) %>%
    .@bayesFactor %>%
    .$bf %>%
    exp() %>%
    bf2str()
  
  bf <- weights %>% 
    nest(d = -c(group, `Group name`)) %>%
    mutate(
      bf = map(d, ~ select(., sameGroup, weight) %>%
                 pivot_wider(
                   names_from = sameGroup, 
                   values_from = weight,
                   values_fn = list
                 ) %$%
                 ttestBF(`Same group`[[1]], `Different groups`[[1]]))
    ) 
  
  bf$BF <- sapply(1:nrow(bf), function(i) bf2str(exp(bf$bf[[i]]@bayesFactor$bf)))
  
  dw <- .1
  trust <- weights %>%
    ggplot(aes(x = sameGroup, y = weight, 
               colour = `Group name`, fill = `Group name`)) +
    geom_hline(yintercept = starting_weight, 
               linetype = 'dashed') +
    geom_line(aes(group = id), alpha = .25) +
    geom_split_violin(aes(x = nudge(sameGroup, dw),
                          group = sameGroup), width = .9,
                      colour = NA) +
    geom_boxplot(outlier.shape = NA, size = 1, width = dw/2,
                 aes(x = nudge(sameGroup, dw), 
                     group = sameGroup),
                 colour = 'black') +
    geom_segment(x = 1, xend = 2, y = 1, yend = 1, colour = 'black') +
    geom_label(y = 1, x = 1.5, colour = 'black', fill = 'white',
               aes(label = paste0('BF = ', BF)), 
               data = bf) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
    coord_cartesian(clip = F) +
    facet_grid(~group) +
    labs(x = 'Group membership with advisor', y = 'Weight given to advice') +
    simulation
  
  print(trust)
  # caption = "Simulated trust for average agents.  Simulated agents' trust in other agents at the end of the simulation. Individual lines show the average trust for an agent in those of the same or different group. Violins and boxplots show the distributions of these averages. The groups are arbitrarily named and separate agents by bias strength (whether the bias is positive or negative). Both groups contain some agents with pronounced biases and some with negligible biases.  The dashed line indicates the starting trust level between all agents in the simulation."
}

# Plot bias evolution for each model
biases <- NULL
for (m in models[c(2, 4)]) {
  x <- select(m$model$agents, id, decision, bias)
  biases <- x %>%
    mutate(
      model = length(unique(biases$model)),
      group = rep(
        if_else(x$bias[x$decision == 1] > 0, 'Right', 'Left'),
        m$parameters$n_decisions
      )
    ) %>%
    rbind(biases)
}

biases %>% 
  mutate(model = factor(model)) %>%
  ggplot(aes(x = decision, y = bias, colour = group)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = paste0(id)), alpha = .25) +
  stat_summary(geom = 'line', aes(group = group), size = 1, fun = median) +
  facet_wrap(~model, labeller = label_both)
# Interesting that the bias updating actually reduces polarisation here!
# Not that it necessarily gets agents closer to the truth...

```

Above we see that updating biases actually _decreases_ polarisation.
This is probably because advice from the other camp tends to draw biases together, while there is relatively little inflation of biases from agreeing extreme opinions (which tend rather to simply stay at the extremes).
If biases were accompanied by a confidence instead... but maybe this is what the weights are supposed to achieve. 
Polarisation might come out of e.g. trying to appeal to a base, but doesn't seem to come out of genuine attempts to form (albeit biased) estimates of true things in the world.

These models assume that evidence (truth of the world) is a shared feature bringing people together. 
Some things in the modern world seem more like the same evidence is taken as bolstering the case for alternative (competing) accounts - e.g. BLM shows liberals that black people are oppressed and conservatives that they are violent.
Maybe worth modelling this? 
On the other hand, even in those cases the ground truth facts usually point to a (variously located) middle-ground truth which is less extreme than either interpretation?

### Can we make bias updating increase polarisation

How about making biases more pronounced to begin with? 

```{r}

starting_weight <- .1
parameters <- data.frame(
  n_agents = 40,
  n_decisions = 5000,
  conf = c(T, T, F, F),
  bias_mean = 3,
  bias_sd = 1,
  sensitivity_sd = 1,
  trust_volatility_mean = .05,
  trust_volatility_sd = .01,
  bias_volatility_mean = 0,
  bias_volatility_sd = c(0, .05, 0, .05),
  starting_graph = .05,
  randomSeed = 20201014
)

models <- runSimulations(parameters, cores = nrow(parameters))

for (m in models) {
  networkGraph(
    m, 
    mark.groups = list(
      which(V(m$model$graphs[[1]])$bias <= 0),
      which(V(m$model$graphs[[1]])$bias > 0)
    ), 
    layout = layout_nicely
  ) 
  
  biasGraph(m) %>% print()
  
  weights <- m$model$graphs[[m$parameters$n_decisions]] %>% 
    edge_attr() %>%
    as_tibble() %>%
    mutate(
      `Group name` = factor(if_else(headBias > 0, 'Right', 'Left')), 
      group = factor(paste0(`Group name`, '\n')),
      sameGroup = factor(if_else(
        sign(headBias) == sign(tailBias), 
        'Same group', 
        'Different groups'
      )),
      id = factor(head_of(
        m$model$graphs[[m$parameters$n_decisions]], 
        E(m$model$graphs[[m$parameters$n_decisions]])
      ))
    ) %>%
    group_by(id, group, sameGroup, `Group name`) %>%
    summarise(weight = mean(weight), .groups = 'drop')
  
  ez::ezANOVA(
    data = weights, 
    dv = weight, 
    wid = id, 
    within = sameGroup, 
    between = group,
    type = 2
  ) %>% print()
  
  bf <- weights %>% 
    select(id, `Group name`, weight) %>%
    pivot_wider(
      names_from = `Group name`, 
      values_from = weight,
      values_fn = list
    ) %$%
    ttestBF(Left[[1]], Right[[1]]) %>%
    .@bayesFactor %>%
    .$bf %>%
    exp() %>%
    bf2str()
  
  bf <- weights %>% 
    nest(d = -c(group, `Group name`)) %>%
    mutate(
      bf = map(d, ~ select(., sameGroup, weight) %>%
                 pivot_wider(
                   names_from = sameGroup, 
                   values_from = weight,
                   values_fn = list
                 ) %$%
                 ttestBF(`Same group`[[1]], `Different groups`[[1]]))
    ) 
  
  bf$BF <- sapply(1:nrow(bf), function(i) bf2str(exp(bf$bf[[i]]@bayesFactor$bf)))
  
  dw <- .1
  trust <- weights %>%
    ggplot(aes(x = sameGroup, y = weight, 
               colour = `Group name`, fill = `Group name`)) +
    geom_hline(yintercept = starting_weight, 
               linetype = 'dashed') +
    geom_line(aes(group = id), alpha = .25) +
    geom_split_violin(aes(x = nudge(sameGroup, dw),
                          group = sameGroup), width = .9,
                      colour = NA) +
    geom_boxplot(outlier.shape = NA, size = 1, width = dw/2,
                 aes(x = nudge(sameGroup, dw), 
                     group = sameGroup),
                 colour = 'black') +
    geom_segment(x = 1, xend = 2, y = 1, yend = 1, colour = 'black') +
    geom_label(y = 1, x = 1.5, colour = 'black', fill = 'white',
               aes(label = paste0('BF = ', BF)), 
               data = bf) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
    coord_cartesian(clip = F) +
    facet_grid(~group) +
    labs(x = 'Group membership with advisor', y = 'Weight given to advice') +
    simulation
  
  print(trust)
  # caption = "Simulated trust for average agents.  Simulated agents' trust in other agents at the end of the simulation. Individual lines show the average trust for an agent in those of the same or different group. Violins and boxplots show the distributions of these averages. The groups are arbitrarily named and separate agents by bias strength (whether the bias is positive or negative). Both groups contain some agents with pronounced biases and some with negligible biases.  The dashed line indicates the starting trust level between all agents in the simulation."
}

# Plot bias evolution for each model
biases <- NULL
for (m in models[c(2, 4)]) {
  modelNum <- length(unique(biases$model))
  x <- select(m$model$agents, id, decision, bias)
  biases <- x %>%
    mutate(
      model = modelNum,
      group = rep(
        if_else(x$bias[x$decision == 1] > 0, 'Right', 'Left'),
        m$parameters$n_decisions
      )
    ) %>%
    rbind(biases)
  
  # animation
  if (F) {
    p <- paste0(tempdir(), '/anim_', modelNum)
    dir.create(p)
    gs <- list(
      which(V(m$model$graphs[[1]])$bias <= 0),
      which(V(m$model$graphs[[1]])$bias > 0)
    )
    coords <- NULL
    for (i in 1:length(m$model$graphs)) {
      g <- m$model$graphs[[i]]
      png(filename = paste0(p, '/', sprintf('%04i', i), '.png'))
      plotGraph(m, i, activeColours = F, layout = function(x) layout_with_fr(x, coords = coords, start.temp = 0.1), mark.groups = gs)
      dev.off()
      coords <- layout_with_fr(g, coords = coords, start.temp = 0.1)
    }
    gifski(
      list.files(p, full.names = T), 
      gif_file = paste0('figures/network-anim_', modelNum, '.gif'),
      width = 480, 
      height = 480, 
      delay = 0,
      loop = T,
      progress = F
    )
    unlink(p)
  }
}

biases %>% 
  mutate(model = factor(model)) %>%
  ggplot(aes(x = decision, y = bias, colour = group)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = paste0(id)), alpha = .25) +
  stat_summary(geom = 'line', aes(group = group), size = 1, fun = median) +
  facet_wrap(~model, labeller = label_both)

```

In this long-view version we see initial polariasation as agents with differing biases become aware of other agents' biases and coalesce into groups. 
While this is going on, the slower process of bias updating is also occurring, and the groups are slowly but surely coming to believe similar (more accurate) things about the world. 
After a while, the similarity in beliefs leads to a repairing of the network connections between groups, which depolarises the network structure.
Eventually, this erodes the difference in trust between members of different groups (indeed the groups are nigh-indistinguishable).

### Models where one group is closer to the truth

```{r}

starting_weight <- .1
truth_fun <- function(model, d) .75
parameters <- data.frame(
  n_agents = 20,
  n_decisions = 500,
  conf = c(T, T, F, F),
  bias_mean = 1,
  bias_sd = 1,
  sensitivity_sd = 1,
  trust_volatility_mean = .05,
  trust_volatility_sd = .01,
  bias_volatility_mean = 0,
  bias_volatility_sd = c(0, .05, 0, .05),
  starting_graph = starting_weight,
  randomSeed = 20201014
)
parameters$truth_fun <- c(truth_fun, truth_fun, truth_fun, truth_fun)

models <- runSimulations(parameters, cores = nrow(parameters))

for (m in models) {
  networkGraph(
    m, 
    mark.groups = list(
      which(V(m$model$graphs[[1]])$bias <= 0),
      which(V(m$model$graphs[[1]])$bias > 0)
    ), 
    layout = layout_nicely
  ) 
  
  biasGraph(m) %>% print()
  
  weights <- m$model$graphs[[m$parameters$n_decisions]] %>% 
    edge_attr() %>%
    as_tibble() %>%
    mutate(
      `Group name` = factor(if_else(headBias > 0, 'Right', 'Left')), 
      group = factor(paste0(`Group name`, '\n')),
      sameGroup = factor(if_else(
        sign(headBias) == sign(tailBias), 
        'Same group', 
        'Different groups'
      )),
      id = factor(head_of(
        m$model$graphs[[m$parameters$n_decisions]], 
        E(m$model$graphs[[m$parameters$n_decisions]])
      ))
    ) %>%
    group_by(id, group, sameGroup, `Group name`) %>%
    summarise(weight = mean(weight), .groups = 'drop')
  
  ez::ezANOVA(
    data = weights, 
    dv = weight, 
    wid = id, 
    within = sameGroup, 
    between = group,
    type = 2
  ) %>% print()
  
  bf <- weights %>% 
    select(id, `Group name`, weight) %>%
    pivot_wider(
      names_from = `Group name`, 
      values_from = weight,
      values_fn = list
    ) %$%
    ttestBF(Left[[1]], Right[[1]]) %>%
    .@bayesFactor %>%
    .$bf %>%
    exp() %>%
    bf2str()
  
  bf <- weights %>% 
    nest(d = -c(group, `Group name`)) %>%
    mutate(
      bf = map(d, ~ select(., sameGroup, weight) %>%
                 pivot_wider(
                   names_from = sameGroup, 
                   values_from = weight,
                   values_fn = list
                 ) %$%
                 ttestBF(`Same group`[[1]], `Different groups`[[1]]))
    ) 
  
  bf$BF <- sapply(1:nrow(bf), function(i) bf2str(exp(bf$bf[[i]]@bayesFactor$bf)))
  
  dw <- .1
  trust <- weights %>%
    ggplot(aes(x = sameGroup, y = weight, 
               colour = `Group name`, fill = `Group name`)) +
    geom_hline(yintercept = starting_weight, 
               linetype = 'dashed') +
    geom_line(aes(group = id), alpha = .25) +
    geom_split_violin(aes(x = nudge(sameGroup, dw),
                          group = sameGroup), width = .9,
                      colour = NA) +
    geom_boxplot(outlier.shape = NA, size = 1, width = dw/2,
                 aes(x = nudge(sameGroup, dw), 
                     group = sameGroup),
                 colour = 'black') +
    geom_segment(x = 1, xend = 2, y = 1, yend = 1, colour = 'black') +
    geom_label(y = 1, x = 1.5, colour = 'black', fill = 'white',
               aes(label = paste0('BF = ', BF)), 
               data = bf) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
    coord_cartesian(clip = F) +
    facet_grid(~group) +
    labs(x = 'Group membership with advisor', y = 'Weight given to advice') +
    simulation
  
  print(trust)
  # caption = "Simulated trust for average agents.  Simulated agents' trust in other agents at the end of the simulation. Individual lines show the average trust for an agent in those of the same or different group. Violins and boxplots show the distributions of these averages. The groups are arbitrarily named and separate agents by bias strength (whether the bias is positive or negative). Both groups contain some agents with pronounced biases and some with negligible biases.  The dashed line indicates the starting trust level between all agents in the simulation."
}

# Plot bias evolution for each model
biases <- NULL
for (m in models[c(2, 4)]) {
  x <- select(m$model$agents, id, decision, bias)
  biases <- x %>%
    mutate(
      model = length(unique(biases$model)),
      group = rep(
        if_else(x$bias[x$decision == 1] > 0, 'Right', 'Left'),
        m$parameters$n_decisions
      )
    ) %>%
    rbind(biases)
}

biases %>% 
  mutate(model = factor(model)) %>%
  ggplot(aes(x = decision, y = bias, colour = group)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = paste0(id)), alpha = .25) +
  stat_summary(geom = 'line', aes(group = group), size = 1, fun = median) +
  facet_wrap(~model, labeller = label_both)
# Interesting that the bias updating actually reduces polarisation here!
# Not that it necessarily gets agents closer to the truth...

```

Where agents keep the same biases they started with, the group who are closest to the true answer show greater trust in their own group compared to the other group. 
Those agents in the group which gets things wrong seem to show a much attenuated effect, vanishing almost entirely in the confidence-weighted case.
Where agents' biases change according to their experience of final decisions, trust is high and not well differentiated between groups.
This is probably because agents quickly arrive at similar biases across the whole population thanks to the double-counting of the true value between the initial decision and the advice.

### Do we still see all these effects if we add weighted advice selection to the model?

```{r}

starting_weight <- .1
parameters <- data.frame(
  n_agents = 20,
  n_decisions = 500,
  conf = c(T, T, F, F),
  bias_mean = 1,
  bias_sd = 1,
  sensitivity_sd = 1,
  trust_volatility_mean = .05,
  trust_volatility_sd = .01,
  bias_volatility_mean = 0,
  bias_volatility_sd = c(0, .05, 0, .05),
  starting_graph = starting_weight,
  randomSeed = 20201014,
  weighted_sampling = 1
)

models <- runSimulations(parameters, cores = nrow(parameters))

for (m in models) {
  networkGraph(
    m, 
    mark.groups = list(
      which(V(m$model$graphs[[1]])$bias <= 0),
      which(V(m$model$graphs[[1]])$bias > 0)
    ), 
    layout = layout_nicely
  ) 
  
  biasGraph(m) %>% print()
  
  weights <- m$model$graphs[[m$parameters$n_decisions]] %>% 
    edge_attr() %>%
    as_tibble() %>%
    mutate(
      `Group name` = factor(if_else(headBias > 0, 'Right', 'Left')), 
      group = factor(paste0(`Group name`, '\n')),
      sameGroup = factor(if_else(
        sign(headBias) == sign(tailBias), 
        'Same group', 
        'Different groups'
      )),
      id = factor(head_of(
        m$model$graphs[[m$parameters$n_decisions]], 
        E(m$model$graphs[[m$parameters$n_decisions]])
      ))
    ) %>%
    group_by(id, group, sameGroup, `Group name`) %>%
    summarise(weight = mean(weight), .groups = 'drop')
  
  ez::ezANOVA(
    data = weights, 
    dv = weight, 
    wid = id, 
    within = sameGroup, 
    between = group,
    type = 2
  ) %>% print()
  
  bf <- weights %>% 
    select(id, `Group name`, weight) %>%
    pivot_wider(
      names_from = `Group name`, 
      values_from = weight,
      values_fn = list
    ) %$%
    ttestBF(Left[[1]], Right[[1]]) %>%
    .@bayesFactor %>%
    .$bf %>%
    exp() %>%
    bf2str()
  
  bf <- weights %>% 
    nest(d = -c(group, `Group name`)) %>%
    mutate(
      bf = map(d, ~ select(., sameGroup, weight) %>%
                 pivot_wider(
                   names_from = sameGroup, 
                   values_from = weight,
                   values_fn = list
                 ) %$%
                 ttestBF(`Same group`[[1]], `Different groups`[[1]]))
    ) 
  
  bf$BF <- sapply(1:nrow(bf), function(i) bf2str(exp(bf$bf[[i]]@bayesFactor$bf)))
  
  dw <- .1
  trust <- weights %>%
    ggplot(aes(x = sameGroup, y = weight, 
               colour = `Group name`, fill = `Group name`)) +
    geom_hline(yintercept = starting_weight, 
               linetype = 'dashed') +
    geom_line(aes(group = id), alpha = .25) +
    geom_split_violin(aes(x = nudge(sameGroup, dw),
                          group = sameGroup), width = .9,
                      colour = NA) +
    geom_boxplot(outlier.shape = NA, size = 1, width = dw/2,
                 aes(x = nudge(sameGroup, dw), 
                     group = sameGroup),
                 colour = 'black') +
    geom_segment(x = 1, xend = 2, y = 1, yend = 1, colour = 'black') +
    geom_label(y = 1, x = 1.5, colour = 'black', fill = 'white',
               aes(label = paste0('BF = ', BF)), 
               data = bf) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
    coord_cartesian(clip = F) +
    facet_grid(~group) +
    labs(x = 'Group membership with advisor', y = 'Weight given to advice') +
    simulation
  
  print(trust)
  # caption = "Simulated trust for average agents.  Simulated agents' trust in other agents at the end of the simulation. Individual lines show the average trust for an agent in those of the same or different group. Violins and boxplots show the distributions of these averages. The groups are arbitrarily named and separate agents by bias strength (whether the bias is positive or negative). Both groups contain some agents with pronounced biases and some with negligible biases.  The dashed line indicates the starting trust level between all agents in the simulation."
}

# Plot bias evolution for each model
biases <- NULL
for (m in models[c(2, 4)]) {
  x <- select(m$model$agents, id, decision, bias)
  biases <- x %>%
    mutate(
      model = length(unique(biases$model)),
      group = rep(
        if_else(x$bias[x$decision == 1] > 0, 'Right', 'Left'),
        m$parameters$n_decisions
      )
    ) %>%
    rbind(biases)
}

biases %>% 
  mutate(model = factor(model)) %>%
  ggplot(aes(x = decision, y = bias, colour = group)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = paste0(id)), alpha = .25) +
  stat_summary(geom = 'line', aes(group = group), size = 1, fun = median) +
  facet_wrap(~model, labeller = label_both)
# Interesting that the bias updating actually reduces polarisation here!
# Not that it necessarily gets agents closer to the truth...

```

These simulations show that adding a correlation between the sampling strategy and the advice-taking strategy (i.e. allowing trust to be a third variable affecting both) makes the polarisation effects much more pronounced.
The primary mechanism for this appears to be discouraging agents from seeking advice from those who disagree, thus making the simulations where biases can change following experience far less likely to converge on the true answer. 
To explore whether this mechanism is responsible for the results we look at the setup with a wider gulf between groups, but with a weighted sampling strategy in place.

### Does weighted sampling suppress bias erosion?

```{r}

starting_weight <- .1
parameters <- data.frame(
  n_agents = 40,
  n_decisions = 5000,
  conf = rep(c(T, F), 3),
  bias_mean = 3,
  bias_sd = 1,
  sensitivity_sd = 1,
  trust_volatility_mean = .05,
  trust_volatility_sd = .01,
  bias_volatility_mean = 0,
  bias_volatility_sd = .05,
  starting_graph = .05,
  randomSeed = rep(c(20201014, 202010, 1014), each = 2),
  weighted_sampling = 1
)

models <- runSimulations(parameters, cores = nrow(parameters))

for (m in models) {
  networkGraph(
    m, 
    mark.groups = list(
      which(V(m$model$graphs[[1]])$bias <= 0),
      which(V(m$model$graphs[[1]])$bias > 0)
    ), 
    layout = layout_nicely
  ) 
  
  biasGraph(m) %>% print()
  
  weights <- m$model$graphs[[m$parameters$n_decisions]] %>% 
    edge_attr() %>%
    as_tibble() %>%
    mutate(
      `Group name` = factor(if_else(headBias > 0, 'Right', 'Left')), 
      group = factor(paste0(`Group name`, '\n')),
      sameGroup = factor(if_else(
        sign(headBias) == sign(tailBias), 
        'Same group', 
        'Different groups'
      )),
      id = factor(head_of(
        m$model$graphs[[m$parameters$n_decisions]], 
        E(m$model$graphs[[m$parameters$n_decisions]])
      ))
    ) %>%
    group_by(id, group, sameGroup, `Group name`) %>%
    summarise(weight = mean(weight), .groups = 'drop')
  
  ez::ezANOVA(
    data = weights, 
    dv = weight, 
    wid = id, 
    within = sameGroup, 
    between = group,
    type = 2
  ) %>% print()
  
  bf <- weights %>% 
    select(id, `Group name`, weight) %>%
    pivot_wider(
      names_from = `Group name`, 
      values_from = weight,
      values_fn = list
    ) %$%
    ttestBF(Left[[1]], Right[[1]]) %>%
    .@bayesFactor %>%
    .$bf %>%
    exp() %>%
    bf2str()
  
  bf <- weights %>% 
    nest(d = -c(group, `Group name`)) %>%
    mutate(
      bf = map(d, ~ select(., sameGroup, weight) %>%
                 pivot_wider(
                   names_from = sameGroup, 
                   values_from = weight,
                   values_fn = list
                 ) %$%
                 ttestBF(`Same group`[[1]], `Different groups`[[1]]))
    ) 
  
  bf$BF <- sapply(1:nrow(bf), function(i) bf2str(exp(bf$bf[[i]]@bayesFactor$bf)))
  
  dw <- .1
  trust <- weights %>%
    ggplot(aes(x = sameGroup, y = weight, 
               colour = `Group name`, fill = `Group name`)) +
    geom_hline(yintercept = starting_weight, 
               linetype = 'dashed') +
    geom_line(aes(group = id), alpha = .25) +
    geom_split_violin(aes(x = nudge(sameGroup, dw),
                          group = sameGroup), width = .9,
                      colour = NA) +
    geom_boxplot(outlier.shape = NA, size = 1, width = dw/2,
                 aes(x = nudge(sameGroup, dw), 
                     group = sameGroup),
                 colour = 'black') +
    geom_segment(x = 1, xend = 2, y = 1, yend = 1, colour = 'black') +
    geom_label(y = 1, x = 1.5, colour = 'black', fill = 'white',
               aes(label = paste0('BF = ', BF)), 
               data = bf) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
    coord_cartesian(clip = F) +
    facet_grid(~group) +
    labs(x = 'Group membership with advisor', y = 'Weight given to advice') +
    simulation
  
  print(trust)
  # caption = "Simulated trust for average agents.  Simulated agents' trust in other agents at the end of the simulation. Individual lines show the average trust for an agent in those of the same or different group. Violins and boxplots show the distributions of these averages. The groups are arbitrarily named and separate agents by bias strength (whether the bias is positive or negative). Both groups contain some agents with pronounced biases and some with negligible biases.  The dashed line indicates the starting trust level between all agents in the simulation."
}

# Plot bias evolution for each model
biases <- NULL
for (m in models) {
  modelNum <- length(unique(biases$model))
  x <- select(m$model$agents, id, decision, bias)
  biases <- x %>%
    mutate(
      model = modelNum,
      group = rep(
        if_else(x$bias[x$decision == 1] > 0, 'Right', 'Left'),
        m$parameters$n_decisions
      )
    ) %>%
    rbind(biases)
}

biases %>% 
  mutate(model = factor(model)) %>%
  ggplot(aes(x = decision, y = bias, colour = group)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  # geom_line(aes(group = paste0(id)), alpha = .15) +
  stat_summary(geom = 'line', aes(group = group), size = 1, fun = median) +
  # scale_y_continuous(limits = c(-50, 50)) +
  facet_wrap(~model, labeller = label_both)

```

Somewhat surprisingly, the bias-protecting effects of the weighted sampling strategy are not clearly evident. 
Differences in random seed make a large difference to whether or not the groups converge on the true values.

All simulations show an enduring advice weight advantage for members of the same group, but the correlations between bias strength and advice weight decline in all but one of the simulations. 
This decline is driven by the reduced difference in bias, rather than an increased weight for those who have different biases.

The bias of the groups does not decline in model 1, and in model 2 it spirals out of control for both groups - perhaps it would return towards the truth given time as it appears to in model 3.
In models 0, 4, and 5, the median bias for the groups becomes quite similar, and changes in lockstep thereafter, staying fairly close to the true value (although still at notably unlikely values given the bias is expressed in z-scores).

## Models with agents based on our experiments

Each participant's data is run through a model which has the following structure:
* $P(pick_i) = SoftMax(\frac{V_i}{Vi+Vj})$ where $V$ is the trust placed in an advisor and $_i$ and $_j$ are competing advisors.
* $V_i^t = V_i^{t-1} + f(I^t,A^t)$ where $I^t$ and $A^t$ are the initial estimate and advice on trial $^t$.  
* $f(I, A, F) = \lambda(agree(I,A)\beta C)$ where $\lambda$ is the trust volatility, $\beta$ is the weight given to confidence, and $C$ is the confidence in the initial decision.  
* $agree(I, A) = -1 + 2(sign(I)=sign(A))$
* $F^t = I^t + V_i^t A^t$ where $F^t$ is the final decision on trial $^t$.  

The final confidence judgement is scaled such that it lies between 0 (completely reversed decision) and 1 (completely sure), making its error roughly compatible with the error for picking. 
The picking and confidence errors are averaged to give the prediction error on that trial. 
All parameters ($\lambda$, $\beta$) will be fit to minimise prediction error over the available trials.

```{r}

# Load up some dots task data. Like all of it. Do need to check the ones where 
select_experiment('dotstask')
trials <- trials %>% 
  mutate(uid = factor(paste0(studyId, studyVersion, ' p', pid)))

# Let's have everyone run their data through a model where they are cumulatively 
# updating their trust in an advisor and that is driving their p(pick) and also
# their woa. 


```