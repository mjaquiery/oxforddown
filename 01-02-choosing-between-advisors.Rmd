---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
---

# Psychology of source selection {#chapter-advisor-choice}
\minitoc

<!-- Presentation of the experiments (may want different subsections for each experiment and an extra one for the general discussion). -->

## Experiment 1: Metacognitive-contingent advisors (Lab)

Pescetelli et al. [-@pescetelliRoleDecisionConfidence2018] showed that, in the absence of objective feedback, advice was more influential coming from an advisor who agrees with a participant when that participant is confident (_Bias Sharing_) than coming from an advisor who agrees with a particpant when that participant is unconfident (_Anti Bias_). This provides evidence of a metacognitive sensitivity in the tracking of advice and the updating of advisor utility. Here we investigate whether these effects show up in the domain of advisor selection.

The literature on information exposure and evaluation indicates that people evaluate more favourably information which agrees with their currently-held opinion !TODO[REF], and preferentially seek out information sources which are likely to provide information which agrees with their currently-held opinion [@garrettEchoChambersOnline2009; @searsSelectiveExposureInformation1967]. If this holds true in the context of the judge-advisor system, advice from _Bias Sharing_ advisors ought to be evaluated more favourably (influence should increase) and should be sought more frequently. Given the evidence in favour of the first of these propositions, we here investigate the latter: given a choice, will judges prefer to receive advice from a _Bias Sharing_ advisor over receiving advice from an advisor who does not share the judge’s bias?

Pescetelli et al. [-@pescetelliRoleDecisionConfidence2018] used a judge-advisor system to demonstrate that judges are influenced to a greater extent by advisors who share their biases. Participants played the role of judge in a judge-advisor system, while the advisors were virtual agents whose advice-giving was dependent upon the confidence and correctness of the judges' initial decisions. The advisors were balanced for overall agreement with the judge and objective correctness of advice. We place participants in a similar paradigm in which they are given a choice between advisors, and hypothesise that they will more frequently seek advice from the _Bias Sharing_ advisor than from the _Anti Bias_ advisor.


### Open science

#### Preregistration

The study was preregistered using AsPredicted.org. The preregistration document can be found at [https://aspredicted.org/ze3tn.pdf](https://aspredicted.org/ze3tn.pdf). 

#### Open materials

Experimental materials, including scripts required to run the experiments in MATLAB and scripts required to analyse the data in R, are available from the [GitHub repository](https://github.com/mjaquiery/nofeedback_trust). 

The experimental design was adapted from Pescetelli et al. [-@pescetelliUseMetacognitiveSignals2017], and the major work in the design, as well as the experimental scripts, is due to Niccolo. The full list of changes to the final design can be seen in the commits to the project repository, which began as a fork of [Niccolo's work](https://github.com/chri4354/nofeedback_trust).

#### Open data

Anonymised study data can be found at !TODO[Use a sensible archive format for this study data, archive on OSF, and produce data dictionary]. A preloaded version of the data formatted appropriately for the R scripts is included in the [GitHub repository](https://github.com/mjaquiery/nofeedback_trust).

### Method

```{r load exp1 data, echo = F, include = F}

# Run the analysis script for experiment 1 from the symlinked repository.
exDirs <- c("repos/nofeedback_trust/AdvisorChoice/analysis/")
wd <- setwd(exDirs[1])
source("AdvisorChoice.R")
setwd(wd)

```


#### Participants

`r nrow(participants)` participants ($M_{age}$ = `r round(mean(participants$age))` ±$SD$ `r round(sd(participants$age), 1)`, `r sum(tolower(participants$gender) == 'm')` male, `r sum(tolower(participants$gender) == 'f')` female, `r sum(tolower(participants$gender) != 'm' & tolower(participants$gender) != 'f')` other) recruited from the University of Oxford participant recruitment platforms took part in the experiment. An additional 2 participants attended experimental sessions but their data were not analysed. Participants were compensated for their time with either course credit for a psychology degree, or 10GBP. 

#### Ethics

Ethical approval for the study was granted by the University of Oxford Medical Sciences Interdivisional Research Ethics Committee (Ref: R55382/RE001).

#### Procedure

The experiment consisted of a judge-advisor system with a perceptual decision task (Figure \ref@(fig:ex1-paradigm)). Participants played the role of the judge, and the advisors were played by virtual agents whose answers depended upon the confidence with which the judge reported the initial decision. In the majority of trials (92%), participants were offered advice from virtual advisors. In one third of these trials (‘choice trials’), participants chose which advisor to receive advice from by clicking on their respective portraits appearing at the top and bottom of the screen. On the remaining two thirds of trials (‘forced trials’), participants were forced to take advice from one of the two advisors (equiprobably).  On these trials, the forced advisor’s portrait appeared at the top or bottom of the screen, with a red cross appearing in the other location, which was not selectable. On the remaining 8% of trials, participants received no advice and were given no opportunity to revise their initial decision. These ‘catch trials’ were included to encourage participants to attend to the initial decisions.

```{r ex1-paradigm, fig.align='center', fig.cap="Experiment 1 procedure: The task began with a blank screen containing only a fixation cross and progress bar. Momentarily prior to the onset of the stimuli the fixation cross flickered. The stimuli, two rectangles containing approximately 200 dots each, appeared for 0.16s, one on either side of the fixation cross. Once the stimuli disappeared, a response-collection screen appeared and prompted the participant to indicate their initial decision and its confidence by selecting a point within one of two regions. The left region indicated a decision that the target was on the left, and increasingly-leftwards points within that region indicated increasing confidence in that decision. The right region indicated a decision that the target was on the right, and increasingly-rightwards points within that region indicated increasing confidence in that decision.\\\nNext, the participant was presented with a choice screen. The choice screen displayed two images, one at the top of the screen and one at the bottom. The images were one of the following: an advisor portrait, a silhouette, or a red cross. The red cross was not selectable, forcing participants to choose the other option. The silhouette offered no advice, and was only ever offered as a forced choice. Selecting an advisor image provided the participant with the opinion of that advisor on the trial.\\\nHaving heard the advice, the participant was again presented with the response-collection screen, with a yellow indicator marking their original response. A second (final) judgement was collected using this screen (except on catch trials), and the trial concluded.", out.width="80%", echo=F}
knitr::include_graphics("figures/experiment_01_MATLAB/paradigm.jpg")
```

Each participant completed 363 trials (51 practice trials over 2 blocks + 12 x 26-trial experimental blocks) in which they had to identify the box with the most dots (Figure \@ref(fig:ex1-paradigm)). The difficulty of the task was continually adjusted throughout the experiment using a 2-down, 1-up staircase procedure to keep the participant’s initial decision accuracy at 72%. At the end of each block, participants were notified as to their (final decision) accuracy in the block and given the opportunity to rest for as long as they wished. Throughout the experiment a progress bar provided a graphical indication of the number of trials remaining in the experiment. 

After each block participants were told what percentage of the (final) answers they had provided were correct and allowed to take a short, self-paced break. Prior to the first experimental block, after the final experimental block, and after the 4th and 8th experimental blocks, participants were presented with a questionnaire (Figure \@ref(fig:ex1-questionnaire)). The questionnaire contained 4 questions for each advisor. The questions asked for the judge’s assessment of the advisor’s likeability, trustworthiness, influence, and ability to do the task. The questions presented before the first experimental block were worded prospectively (e.g. ‘How much are you going to like this person?’ as opposed to ‘How much do you like this person?’). Answers were provided by moving a sliding scale below the advisor’s portrait towards the right for more favourable responses (marked ‘extremely’) or towards the left for less favourable responses (marked ‘not at all’).

```{r ex1-questionnaire, fig.align='center', fig.cap="Experiment 1 advisor questionnaire: Participants rated advisors on a number of different dimensions.", out.width="80%", echo=F}
knitr::include_graphics("figures/experiment_01_MATLAB/questionnaire.jpg")
```

Each participant attended the experiment individually, was welcomed and briefed on the experimental procedure, and had their informed consent recorded, before the experiment began. They were seated a comfortable distance in front of a 24’ (1440x900 resolution) computer screen in a small, quiet, and dimly-lit room. The experiment took place wholly on the computer, and lasted around 45 minutes.

The experiment was programmed in MATLAB R2017b [@MATLAB2017] using the Psychtoolbox-3 package [@kleiner2007s], and data analysis was performed using R [@rcoreteamLanguageEnvironmentStatistical2018]. For a full list of packages and software environment information, see !TODO[figure out where to include this stuff. Appendix? Also link to a containerized version of this.]

#### Advisor advice profiles

The advisors are virtual agents whose probability of agreeing with the participant’s decision varies as a function of the participant’s confidence and correctness in the initial decision phase. Table \ref@(tab:ex1-advisor-profiles) illustrates how this relationship functions, and shows that the overall correctness and agreement rates of the advisors is equivalent overall. Importantly, on largest minority of trials, the middle 40%, the advisors are exactly equivalent, meaning these trials can be compared directly without confounds arising from agreement rate and initial confidence.

Table \ref{tab:ex1-advisor-profiles}: Advisor advice profiles
 
```{r ex1-advisor-profiles} 

library(kableExtra)
library(tibble)

tmp <- tribble(
  ~` `, ~`  `, ~`Bias Sharing`, ~`Anti Bias`,
  "Participant correct", "High (top 30%)", 80, 60,
  "Participant correct", "Medium (middle 40%)", 70, 70,
  "Participant correct", "Low (bottom 30%)", 60, 80,
  "Participant incorrect", "Any", 30, 30,
  "Total agreement", "Participant correct", 70, 70,
  "Total agreement", "Participant incorrect", 30, 30
)

kable(tmp, align = c('l', 'l', 'r', 'r')) %>%
  kable_styling() %>%
  column_spec(1, bold = T) %>%
  row_spec(0, bold = F) %>%
  collapse_rows(columns = 1, valign = "top") %>%
  add_header_above(c(" ", 
                     "Initial decision confidence", 
                     "Probability of agreement (%)" = 2))

```

### Result

### Discussion

## Experiment 2: Metacognitive-contingent advisors
 
### Method

### Result

### Discussion

## Experiment 3: Advisor accuracy

### Method

### Result

### Discussion

## Experiment 4: Advisor agreement

### Method

### Result

### Discussion

## Experiment 5: Accuracy vs agreement (Date estimation)

### Method

### Result

### Discussion

## General discussion