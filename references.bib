@Article{sollStrategiesRevisingJudgment2009,
  title = {Strategies for Revising Judgment: {{How}} (and How Well) People Use Others' Opinions.},
  shorttitle = {Strategies for Revising Judgment},
  author = {Jack B. Soll and Richard P. Larrick},
  year = {2009},
  volume = {35},
  pages = {780--805},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0015145},
  abstract = {A basic issue in social influence is how best to change one's judgment in response to learning the opinions of others. This article examines the strategies that people use to revise their quantitative estimates on the basis of the estimates of another person. The authors note that people tend to use 2 basic strategies when revising estimates: choosing between the 2 estimates and averaging them. The authors developed the probability, accuracy, redundancy (PAR) model to examine the relative effectiveness of these two strategies across judgment environments. A surprising result was that averaging was the more effective strategy across a wide range of commonly encountered environments. The authors observed that despite this finding, people tend to favor the choosing strategy. Most participants in these studies would have achieved greater accuracy had they always averaged. The identification of intuitive strategies, along with a formal analysis of when they are accurate, provides a basis for examining how effectively people use the judgments of others. Although a portfolio of strategies that includes averaging and choosing can be highly effective, the authors argue that people are not generally well adapted to the environment in terms of strategy selection.},
  
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  language = {en},
  number = {3},
}
@Article{yanivExploitingWisdomOthers2012,
  title = {Exploiting the {{Wisdom}} of {{Others}} to {{Make Better Decisions}}: {{Suspending Judgment Reduces Egocentrism}} and {{Increases Accuracy}}},
  shorttitle = {Exploiting the {{Wisdom}} of {{Others}} to {{Make Better Decisions}}},
  author = {Ilan Yaniv and Shoham Choshen-Hillel},
  year = {2012},
  month = {dec},
  volume = {25},
  pages = {427--434},
  issn = {1099-0771},
  doi = {10.1002/bdm.740},
  abstract = {Although decision makers often consult other people's opinions to improve their decisions, they fail to do so optimally. One main obstacle to incorporating others' opinions efficiently is one's own opinion. We theorize that decision makers could improve their performance by suspending their own judgment. In three studies, participants used others' opinions to estimate uncertain quantities (the caloric value of foods). In the full-view condition, participants could form independent estimates prior to receiving others' opinions, whereas participants in the blindfold condition could not form prior opinions. We obtained an intriguing blindfold effect. In all studies, the blindfolded participants provided more accurate estimates than did the full-view participants. Several policy-capturing measures indicated that the advantage of the blindfolded participants was due to their unbiased weighting of others' opinions. The full-view participants, in contrast, adhered to their prior opinion and thus failed to exploit the information contained in others' opinions. Moreover, in all three studies, the blindfolded participants were not cognizant of their advantage and expressed less confidence in their estimates than did the full-view participants. The results are discussed in relation to theories of opinion revision and group decision making. Copyright \textcopyright{} 2011 John Wiley \& Sons, Ltd.},
  
  journal = {Journal of Behavioral Decision Making},
  keywords = {advice taking,belief revision,combining opinions,decision making,judgment},
  language = {en},
  number = {5},
}
@Article{troucheVigilantConservatismEvaluating2018,
  title = {Vigilant Conservatism in Evaluating Communicated Information},
  author = {Emmanuel Trouche and Petter Johansson and Lars Hall and Hugo Mercier},
  editor = {Alexander N. Sokolov},
  year = {2018},
  month = {jan},
  volume = {13},
  pages = {e0188825},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0188825},
  abstract = {In the absence of other information, people put more weight on their own opinion than on the opinion of others: they are conservative. Several proximal mechanisms have been suggested to account for this finding. One of these mechanisms is that people cannot access reasons for other people's opinions, but they can access the reasons for their own opinions\textemdash whether they are the actual reasons that led them to hold the opinions (rational access to reasons), or post-hoc constructions (biased access to reasons). In four experiments, participants were asked to provide an opinion, and then faced with another participant's opinion and asked if they wanted to revise their initial opinion. Some questions were manipulated so that the advice participants were receiving was in fact their own opinion, while what they thought was their own opinion was in fact not. In all experiments, the participants were consistently biased towards what they thought was their own opinion, showing that conservativeness cannot be explained by rational access to reasons, which should have favored the advice. One experiment revealed that conservativeness was not decreased under time pressure, suggesting that biased access to reasons is an unlikely explanation for conservativeness. The experiments also suggest that repetition plays a role in advice taking, with repeated opinions being granted more weight than non-fluent opinions. Our results are not consistent with any of the established proximal explanations for conservatism. Instead, we suggest an ultimate explanation\textemdash vigilant conservatism\textemdash that sees conservatism as adaptive since receivers should be wary of senders' interests, as they rarely perfectly converge with theirs.},
  
  journal = {PLOS ONE},
  language = {en},
  number = {1},
}
@Article{ginoEffectsTaskDifficulty2007,
  title = {Effects of Task Difficulty on Use of Advice},
  author = {Francesca Gino and Don A. Moore},
  year = {2007},
  month = {jan},
  volume = {20},
  pages = {21--35},
  issn = {1099-0771},
  doi = {10.1002/bdm.539},
  abstract = {Although prior studies have found that people generally underweight advice from others, such discounting of advice is not universal. Two studies examined the impact of task difficulty on the use of advice. In both studies, the strategy participants used to weigh advice varied with task difficulty even when it should not have. In particular, the results show that people tend to overweight advice on difficult tasks and underweight advice on easy tasks. This pattern held regardless of whether advice was automatically provided or whether people had to seek it out. The paper discusses implications for the circumstances under which people will be open to influence by advisors. Copyright \textcopyright{} 2006 John Wiley \& Sons, Ltd.},
  
  journal = {Journal of Behavioral Decision Making},
  keywords = {advice,biases,comparative judgment,decision-making,difficulty,egocentrism,expert advice,heuristics,improving judgment,information,judgmental weighting,optimism,social prediction,uncertainty},
  language = {en},
  number = {1},
}
@Article{wangWhyDoesAdvice2018,
  title = {Why {{Does Advice Discounting Occur}}? {{The Combined Roles}} of {{Confidence}} and {{Trust}}},
  shorttitle = {Why {{Does Advice Discounting Occur}}?},
  author = {Xiuxin Wang and Xiufang Du},
  year = {2018},
  month = {nov},
  volume = {9},
  pages = {2381},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.02381},
  abstract = {Judges tend to discount the opinions of others even though advice is often helpful in improving their accuracy. The present research proposes that this phenomenon of advice discounting results from the judges' confidence in their initial decision and little trust in advice. Furthermore, the degree of advice discounting may be predicted by the combined roles of confidence and trust. Three studies provide evidence for these hypotheses. Participants were very confident in their initial estimation and had little trust in the advice (study 1). The degree of advice discounting decreased when participants felt less confidence in performing difficult tasks compared with easy tasks (study 2) or when participants placed more trust in advice because the advice was from an expert rather than from a novice (study 3). In addition, confidence and trust predicted the degree of advice discounting across three studies. These findings shed new light on the mechanism underlying advice discounting and advice taking by indicating the combined roles of confidence and trust.},
  
  journal = {Frontiers in Psychology},
  keywords = {advice discounting,advice taking,advisers,confidence,decision making,decision-making,improving judgment,overconfidence,self,strategies,trust},
  language = {English},
}
@Article{ginoAnxietyAdviceAbility2012,
  title = {Anxiety, {{Advice}}, and the {{Ability}} to {{Discem}}: {{Feeling Anxious Motivates Individuals}} to {{Seek}} and {{Use Advice}}},
  author = {Francesca Gino and Alison Wood Brooks and Maurice E Schweitzer},
  year = {2012},
  volume = {102},
  pages = {497--512},
  abstract = {Across 8 experiments, the influence of anxiety on advice seeking and advice taking is described. Anxious individuals are found to be more likely to seek and rely on advice than are those in a neutral emotional state (Experiment 1), but this pattern of results does not generalize to other negatively valenced emotions (Experiment 2). The relationships between anxiety and advice seeking and anxiety and advice taking are mediated by self-confidence; anxiety lowers self-confidence, which increases advice seeking and reliance upon advice (Experiment 3). Although anxiety also impairs information processing, impaired information processing does not mediate the relationship between anxiety and advice taking (Experiment 4). Finally, anxious individuals are found to fail to discriminate between good and bad advice (Experiments 5a-5c), and between advice from advisors with and without a conflict of interest (Experiment 6).},
  
  journal = {Journal of Personality and Social Psychology},
  language = {en},
  number = {3},
}

@Article{seeDetrimentalEffectsPower2011,
  title = {The Detrimental Effects of Power on Confidence, Advice Taking, and Accuracy},
  author = {Kelly E. See and Elizabeth W. Morrison and Naomi B. Rothman and Jack B. Soll},
  year = {2011},
  month = {nov},
  volume = {116},
  pages = {272--285},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2011.07.006},
  abstract = {Incorporating input from others can enhance decision quality, yet often people do not effectively utilize advice. We propose that greater power increases the propensity to discount advice, and that a key mechanism explaining this effect is elevated confidence in one's judgment. We investigate the relationships across four studies: a field survey where working professionals rated their own power and confidence and were rated by coworkers on their level of advice taking; an advice taking task where power and confidence were self-reported; and two advice taking experiments where power was manipulated. Results consistently showed a negative relationship between power and advice taking, and evidence of mediation through confidence. The fourth study also revealed that higher power participants were less accurate in their final judgments. Power can thus exacerbate the tendency for people to overweight their own initial judgment, such that the most powerful decision makers can also be the least accurate.},
  
  journal = {Organizational Behavior and Human Decision Processes},
  keywords = {Advice,average,behavior,bias,confidence,Confidence,decision-making,group judgments,impact,information,Judgment and decision making,Multi-method,organizations,overconfidence,people,Performance-accuracy,Power},
  number = {2},
}
@Article{vanswolForecastingAnotherEnjoyment2011,
  title = {Forecasting Another's Enjoyment versus Giving the Right Answer: {{Trust}}, Shared Values, Task Effects, and Confidence in Improving the Acceptance of Advice},
  shorttitle = {Forecasting Another's Enjoyment versus Giving the Right Answer},
  author = {Lyn M. {Van Swol}},
  year = {2011},
  month = {jan},
  volume = {27},
  pages = {103--120},
  issn = {01692070},
  doi = {10.1016/j.ijforecast.2010.03.002},
  abstract = {In two experiments, participants received advice from another participant on a task either with a correct answer (intellective tasks) or without a correct answer (judgmental task), in which the participant had to make a forecast. In both experiments, the level of trust in the advisor and a perception of the advisor having similar values were important predictors of the acceptance of advice for a judgmental, taste forecast task, whereas advisor confidence was a more important predictor of the acceptance of advice on the intellective task. In Experiment 2, the face-to-face interactions between the decision-maker and the advisor were videotaped and coded. Advisors provided more information to decision-makers for the taste forecast than for the intellective task. Further, whether the advisor provided information to supplement their recommendation or not was a significant predictor of the acceptance of advice on the taste forecast, but not on the intellective task. The results are discussed in the context of previous research on advice, which has predominately used intellective tasks.},
  
  journal = {International Journal of Forecasting},
  language = {en},
  number = {1},
}
@Article{libermanNaiveRealismCapturing2012,
  title = {Na\"ive Realism and Capturing the ``Wisdom of Dyads''},
  author = {Varda Liberman and Julia A. Minson and Christopher J. Bryan and Lee Ross},
  year = {2012},
  month = {mar},
  volume = {48},
  pages = {507--512},
  issn = {00221031},
  doi = {10.1016/j.jesp.2011.10.016},
  abstract = {Two studies provided evidence for the role of na\"ive realism in the failure of individuals to give adequate weight to peer input, and explored two strategies for reducing the impact of this inferential bias. Study 1 demonstrated that dyad members see their own estimates as more ``objective'' than those of their partners and that this difference in perceived objectivity predicts the degree of underweighting. Compelling participants to assess their own versus their partners' objectivity prior to revising estimates decreased underweighting, an effect that was mediated by differences in perceived objectivity. Study 2 showed that the increase in accuracy that results from requiring dyad members to offer joint estimates via discussion is largely retained in subsequent individual estimates. Both studies showed that underweighting is greater when dyad members disagree on the issue about which they are making consensus estimates\textemdash a finding that further supports a ``na\"ive realism'' interpretation of the phenomenon.},
  
  journal = {Journal of Experimental Social Psychology},
  language = {en},
  number = {2},
}
@Article{schultzeInabilityIgnoreUseless2017,
  title = {On the {{Inability}} to {{Ignore Useless Advice}}: {{A Case}} for {{Anchoring}} in the {{Judge}}-{{Advisor}}-{{System}}},
  shorttitle = {On the {{Inability}} to {{Ignore Useless Advice}}},
  author = {Thomas Schultze and Andreas Mojzisch and Stefan Schulz-Hardt},
  year = {2017},
  month = {may},
  volume = {64},
  pages = {170--183},
  issn = {1618-3169, 2190-5142},
  doi = {10.1027/1618-3169/a000361},
  
  journal = {Experimental Psychology},
  keywords = {adjustment,advice taking,anchoring,consequences,counter-explanation,decision-making,forecasts,information,judgment,perspective,selective accessibility,social influence,strategies},
  language = {en},
  number = {3},
}
@Article{rollwageConfidenceDrivesNeural2020,
  title = {Confidence Drives a Neural Confirmation Bias},
  author = {Max Rollwage and Alisa Loosen and Tobias U. Hauser and Rani Moran and Raymond J. Dolan and Stephen M. Fleming},
  year = {2020},
  month = {may},
  volume = {11},
  pages = {2634},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-16278-6},
  abstract = {A prominent source of polarised and entrenched beliefs is confirmation bias, where evidence against one's position is selectively disregarded. This effect is most starkly evident when opposing parties are highly confident in their decisions. Here we combine human magnetoencephalography (MEG) with behavioural and neural modelling to identify alterations in post-decisional processing that contribute to the phenomenon of confirmation bias. We show that holding high confidence in a decision leads to a striking modulation of post-decision neural processing, such that integration of confirmatory evidence is amplified while disconfirmatory evidence processing is abolished. We conclude that confidence shapes a selective neural gating for choice-consistent information, reducing the likelihood of changes of mind on the basis of new information. A central role for confidence in shaping the fidelity of evidence accumulation indicates that metacognitive interventions may help ameliorate this pervasive cognitive bias.},
  copyright = {2020 The Author(s)},
  
  journal = {Nature Communications},
  language = {en},
  number = {1},
}
@Article{hutterSeekingAdviceSampling2016,
  title = {Seeking Advice: {{A}} Sampling Approach to Advice Taking},
  author = {Mandy H{\"u}tter and Fabian Ache},
  year = {2016},
  volume = {11},
  pages = {16},
  abstract = {The present research addresses advice taking from a holistic perspective covering both advice seeking and weighting. We build on previous theorizing that assumes that underweighting of advice results from biased samples of information. That is, decision makers have more knowledge supporting their own judgment than that of another person and thus weight the former stronger than the latter. In the present approach, we assume that participants reduce this informational asymmetry by the sampling of advice and that sampling frequency depends on the information ecology. Advice that is distant from the decision maker's initial estimate should lead to a higher frequency of advice sampling than close advice. Moreover, we assume that advice distant from the decision maker's initial estimate and advice that is supported by larger samples of advisory estimates are weighted more strongly in the final judgment. We expand the classical research paradigm with a sampling phase that allows participants to sample any number of advisory estimates before revising their judgments. Three experiments strongly support these hypotheses, thereby advancing our understanding of advice taking as an adaptive process.},
  
  journal = {Judgment and Decision Making},
  language = {en},
  number = {4},
}
@Article{minsonTwoTangoEffects2011,
  title = {Two to {{Tango}}: {{Effects}} of {{Collaboration}} and {{Disagreement}} on {{Dyadic Judgment}}},
  shorttitle = {Two to {{Tango}}},
  author = {Julia A. Minson and Varda Liberman and Lee Ross},
  year = {2011},
  month = {oct},
  volume = {37},
  pages = {1325--1338},
  issn = {0146-1672, 1552-7433},
  doi = {10.1177/0146167211410436},
  abstract = {Four studies examined dyadic collaboration on quantitative estimation tasks. In accord with the tenets of ``na\"ive realism,'' dyad members failed to give due weight to a partner's estimates, especially those greatly divergent from their own. The requirement to reach joint estimates through discussion increased accuracy more than reaching agreement through a mere exchange of numerical ``bids.'' However, even the latter procedure increased accuracy, relative to that of individual estimates (Study 1). Accuracy feedback neither increased weight given to partner's subsequent estimates nor produced improved accuracy (Study 2). Long-term dance partners, who shared a positive estimation bias, failed to improve accuracy when estimating their performance scores (Study 3). Having dyad members ask questions about the bases of partner's estimates produced greater yielding and accuracy increases than having them explain their own estimates (Study 4). The latter two studies provided additional direct and indirect evidence for the role of na\"ive realism.},
  
  journal = {Personality and Social Psychology Bulletin},
  language = {en},
  number = {10},
}
@Article{moussaidSocialInfluenceCollective2013,
  title = {Social {{Influence}} and the {{Collective Dynamics}} of {{Opinion Formation}}},
  author = {Mehdi Moussa{\"i}d and Juliane E. K{\"a}mmer and Pantelis P. Analytis and Hansj{\~A}{\P}rg Neth},
  year = {2013},
  month = {nov},
  volume = {8},
  pages = {e78433},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0078433},
  abstract = {Social influence is the process by which individuals adapt their opinion, revise their beliefs, or change their behavior as a result of social interactions with other people. In our strongly interconnected society, social influence plays a prominent role in many self-organized phenomena such as herding in cultural markets, the spread of ideas and innovations, and the amplification of fears during epidemics. Yet, the mechanisms of opinion formation remain poorly understood, and existing physics-based models lack systematic empirical validation. Here, we report two controlled experiments showing how participants answering factual questions revise their initial judgments after being exposed to the opinion and confidence level of others. Based on the observation of 59 experimental subjects exposed to peer-opinion for 15 different items, we draw an influence map that describes the strength of peer influence during interactions. A simple process model derived from our observations demonstrates how opinions in a group of interacting people can converge or split over repeated interactions. In particular, we identify two major attractors of opinion: (i) the expert effect, induced by the presence of a highly confident individual in the group, and (ii) the majority effect, caused by the presence of a critical mass of laypeople sharing similar opinions. Additional simulations reveal the existence of a tipping point at which one attractor will dominate over the other, driving collective opinion in a given direction. These findings have implications for understanding the mechanisms of public opinion formation and managing conflicting situations in which self-confident and better informed minorities challenge the views of a large uninformed majority.},
  
  journal = {PLOS ONE},
  keywords = {Collective human behavior,Complex systems,Decision trees,Experimental psychology,Psychological attitudes,Social influence,Social psychology,Sociology of knowledge},
  language = {en},
  number = {11},
}
@Article{schultzeEffectsDistanceInitial2015,
  title = {Effects of Distance between Initial Estimates and Advice on Advice Utilization},
  author = {Thomas Schultze and Anne-Fernandine Rakotoarisoa and Stefan Schulz-Hardt},
  year = {2015},
  volume = {10},
  pages = {28},
  abstract = {Six experiments investigated how the distance between one's initial opinion and advice relates to advice utilization. Going beyond previous research, we relate advice distance to both relative adjustments and absolute adjustments towards the advice, and we also investigate a second mode of advice utilization, namely confidence shifts due to social validation. Whereas previous research suggests that advice is weighted less the more it differs from one's initial opinion, we consistently find evidence of a curvilinear pattern. Advice is weighted less when advice distance is low and when it is high. This is in particular because individuals are much more likely to retain their initial opinions in the light of near advice. Also, absolute opinion adjustments towards the advice increases in a monotone fashion as advice distance increases. This finding is in contrast to the predictions of the theoretical framework previous studies on advice distance are based on, social judgment theory. Instead, they data are more in line with a simple stimulus-response model suggesting that absolute adjustments towards the advice increase with advice distance but\textemdash potentially\textemdash with diminished sensitivity. Finally, our data show that advice can be utilized even when it receives zero weight during belief revision. The closer advice was to the initial opinions, the more it served as a means for social validation, increasing decision-makers' confidence in the accuracy of their final opinions. Thus, our findings suggest that advice utilization is a more complex function of advice distance than previously assumed.},
  
  journal = {Judgment and Decision Making},
  language = {en},
  number = {2},
}
@Article{tostPowerCompetitivenessAdvice2012,
  title = {Power, Competitiveness, and Advice Taking: {{Why}} the Powerful Don't Listen},
  shorttitle = {Power, Competitiveness, and Advice Taking},
  author = {Leigh Plunkett Tost and Francesca Gino and Richard P. Larrick},
  year = {2012},
  month = {jan},
  volume = {117},
  pages = {53--65},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2011.10.001},
  abstract = {Four experiments test the prediction that feelings of power lead individuals to discount advice received from both experts and novices. Experiment 1 documents a negative relationship between subjective feelings of power and use of advice. Experiments 2 and 3 further show that individuals experiencing neutral and low levels of power weigh advice from experts and experienced advisors more heavily than advice from novices, but individuals experiencing high levels of power discount both novice and expert advice. Experiments 3 and 4 demonstrate that this tendency of individuals experiencing high levels of power to discount advice from experts and novices equally is mediated by feelings of competitiveness (Experiment 3) and confidence (Experiments 3 and 4). Finally, Experiment 4 shows that inducing high power individuals to feel cooperative with their advisors can mitigate this tendency, leading them to weigh expert advice more heavily than advice from novices. Theoretical and practical contributions are discussed. (C) 2011 Elsevier Inc. All rights reserved.},
  
  journal = {Organizational Behavior and Human Decision Processes},
  keywords = {accuracy,Advice taking,adviser,Competition,Competitive mindset,Confidence,expert   advice,Expertise,improving judgment,mediation,multilevel theory,opinions,Power,self,team decision-making,validation},
  language = {English},
  number = {1},
}
@Article{rakoczyYoungChildrenHeed2015,
  title = {Young Children Heed Advice Selectively},
  author = {Hannes Rakoczy and Christoph Ehrling and Paul L. Harris and Thomas Schultze},
  year = {2015},
  month = {oct},
  volume = {138},
  pages = {71--87},
  issn = {00220965},
  doi = {10.1016/j.jecp.2015.04.007},
  abstract = {A rational strategy to update and revise one's uncertain beliefs is to take advice by other agents who are better informed. Adults routinely engage in such advice taking in systematic and selective ways depending on relevant characteristics such as reliability of advisors. The current study merged research in social and developmental psychology to examine whether children also adjust their initial judgment to varying degrees depending on the characteristics of their advisors. Participants aged 3 to 6 years played a game in which they made initial judgments, received advice, and subsequently made final judgments. They systematically revised their judgments in light of the advice, and they did so selectively as a function of advisor expertise. They made greater adjustments to their initial judgment when advised by an apparently knowledgeable informant. This suggests that the pattern of advice taking studied in social psychology has its roots in early development.},
  
  journal = {Journal of Experimental Child Psychology},
  language = {en},
}
@Article{sniezekTrustConfidenceExpertise2001,
  title = {Trust, {{Confidence}}, and {{Expertise}} in a {{Judge}}-{{Advisor System}}},
  author = {Janet A. Sniezek and Lyn M. {Van Swol}},
  year = {2001},
  month = {mar},
  volume = {84},
  pages = {288--307},
  issn = {0749-5978},
  doi = {10.1006/obhd.2000.2926},
  abstract = {The relationship between trust, confidence, and expertise in Judge-Advisor Systems is examined in two experiments with Judge-Advisor pairs, one with strangers and another with participants in ongoing relationships. There was expertise asymmetry so that Judges had less expertise than their Advisors. The dyads could receive money for accurate Judge decisions. Either the Judge or Advisor had the power to allocate this money between dyad members, before task interaction in study one and after task completion in study two. Because Judges were more dependent on Advisors than vice versa, it was predicted that trust would be more important to Judges. Results were supportive. Judges had higher and more variable ratings of trust in their partner than did Advisors, suggesting that Judges were more motivated to evaluate trust. High confidence by Advisors had a positive impact on Judges' ratings of trust and tendency to follow their advice. Judges' trust in their Advisors was significantly related their taking the advice and being confident in their final decisions. Although participants in study two had higher levels of trust in their partners, they allocated less money to them. The implications for establishing trust are discussed.},
  
  journal = {Organizational Behavior and Human Decision Processes},
  number = {2},
}
@Article{swolFactorsAffectingAcceptance2005,
  title = {Factors Affecting the Acceptance of Expert Advice},
  author = {Lyn M. Swol and Janet A. Sniezek},
  year = {2005},
  month = {sep},
  volume = {44},
  pages = {443--461},
  issn = {01446665},
  doi = {10.1348/014466604X17092},
  
  journal = {British Journal of Social Psychology},
  language = {en},
  number = {3},
}
@Article{onkalRelativeInfluenceAdvice2009,
  title = {The {{Relative Influence}} of {{Advice From Human Experts}} and {{Statistical Methods}} on {{Forecast Adjustments}}},
  author = {Dilek {\"O}nkal and Paul Goodwin and Mary Thomson and {Sinan M.} G{\"o}n{\"u}l and Andrew Pollock},
  year = {2009},
  month = {oct},
  volume = {22},
  pages = {390--409},
  issn = {0894-3257},
  doi = {10.1002/bdm.637},
  abstract = {Decision makers and forecasters often receive advice from different sources including human experts and statistical methods. This research examines, in the context of stock price forecasting, how the apparent source of the advice affects the attention that is paid to it when the mode of delivery of the advice is identical for both sources. In Study L two groups of participants were given the same advised point and interval forecasts. One group was told that these were the advice of a human expert and the other that they were generated by a statistical forecasting method. The participants were then asked to adjust forecasts they had previously made in light of this advice. While in both cases the advice led to improved point forecast accuracy and better calibration of the prediction intervals, the advice which apparently emanated from a statistical method was discounted much more severely. In Study 2, participants were provided with advice from two Sources. When the participants were told that both sources were either human experts or both were statistical methods, the apparent statistical-based advice had the same influence on the adjusted estimates as the advice that appeared to conic from a human expert. However when the apparent Sources of advice were different, much greater attention was paid to the advice that apparently came from a human expert. Theories of advice utilization are used to identify why the advice of a human expert is likely to be preferred to advice from a statistical method. Copyright (C) 2009 John Wiley \& Sons, Ltd.},
  
  journal = {Journal of Behavioral Decision Making},
  keywords = {accuracy,advice,advice utilization,aggregation,decision-making,forecast adjustment,forecasting,improving judgment,information,judgmental adjustment,opinions,prediction,role of experts,self-referent,source   framing,uncertainty},
  language = {English},
  number = {4},
}
@Article{onkalEvaluatingExpertAdvice2017,
  title = {Evaluating Expert Advice in Forecasting: {{Users}}' Reactions to Presumed vs. Experienced Credibility},
  shorttitle = {Evaluating Expert Advice in Forecasting},
  author = {Dilek {\"O}nkal and {Sinan M.} G{\"o}n{\"u}l and Paul Goodwin and Mary Thomson and Esra {\"O}z},
  year = {2017},
  month = {jan},
  volume = {33},
  pages = {280--297},
  issn = {0169-2070},
  doi = {10.1016/j.ijforecast.2015.12.009},
  abstract = {In expert knowledge elicitation (EKE) for forecasting, the perceived credibility of an expert is likely to affect the weighting attached to their advice. Four experiments have investigated the extent to which the implicit weighting depends on the advisor's experienced (reflecting the accuracy of their past forecasts), or presumed (based on their status) credibility. Compared to a control group, advice from a source with a high experienced credibility received a greater weighting, but having a low level of experienced credibility did not reduce the weighting. In contrast, a high presumed credibility did not increase the weighting relative to a control group, while a low presumed credibility decreased it. When there were opportunities for the two types of credibility to interact, a high experienced credibility tended to eclipse the presumed credibility if the advisees were non-experts. However, when the advisees were professionals, both the presumed and experienced credibility of the advisor were influential in determining the weight attached to the advice.},
  
  journal = {International Journal of Forecasting},
  keywords = {Advice,Experienced credibility,Forecasting,Information use,Presumed credibility,Source credibility},
  language = {en},
  number = {1},
}
@Article{bonnerGroupJudgmentAdviceTaking2014,
  title = {Group {{Judgment}} and {{Advice}}-{{Taking}}: {{The Social Context Underlying CEO Compensation Decisions}}},
  shorttitle = {Group {{Judgment}} and {{Advice}}-{{Taking}}},
  author = {Bryan L. Bonner and Brian D. Cadman},
  year = {2014},
  month = {dec},
  volume = {18},
  pages = {302--317},
  issn = {1089-2699},
  doi = {10.1037/gdn0000011},
  abstract = {Groups are often tasked with making important organizational decisions. For example, CEO compensation judgments are made by groups of decision makers with no specialized compensation training who receive advice from a third party with a potential bias. This study seeks to understand the effects of this challenging context on decision making. We explore whether and how decision makers adjust their judgments, considering the potential for advisor bias. This is an essential issue in CEO compensation that is difficult to assess through traditional archival research based on publicly available data. Our study explores how decision makers, in the context of compensation committees, process and use advice provided by external parties. Our findings illustrate that individuals adjust for known conflicts of interest in the information provided to them. However, we do not find that individuals discount lavish advice to a greater extent than more modest advice, and the group decision-making process fails to correct for this tendency.},
  
  journal = {Group Dynamics-Theory Research and Practice},
  keywords = {auditor independence,biased   advice,conflict of interest,conflicts-of-interest,demonstrability,executive compensation,executive-compensation,group judgment,individuals,information,models,negotiation,performance,schemes,social decision schemes},
  language = {English},
  number = {4},
}
@Article{sniezekImprovingJudgementPrepaid2004,
  title = {Improving Judgement with Prepaid Expert Advice},
  author = {Janet A. Sniezek and Gunnar E. Schrah and Reeshad S. Dalal},
  year = {2004},
  month = {jul},
  volume = {17},
  pages = {173--190},
  issn = {1099-0771},
  doi = {10.1002/bdm.468},
  abstract = {Decision makers (``Judges'') often make decisions after obtaining advice from an Advisor. The two parties often share a psychological ``contract'' about what each contributes in expertise to the decision and receives in monetary outcomes from it. In a laboratory experiment, we varied Advisor Experitise and the opportunity for monetary rewards. As expected, these manipulations influenced advice quality, advice taking, and Judge post-advice decision quality. The main contribution of the study, however, was the manipulation of the timing of monetary rewards (before or after the advising interaction). We found, as predicted, that committing money for expert\textemdash but not novice\textemdash advice increases Judges' use of advice and their subsequent estimation accuracy. Implications for advice giving and taking are discussed. Copyright \textcopyright{} 2004 John Wiley \& Sons, Ltd.},
  
  journal = {Journal of Behavioral Decision Making},
  keywords = {advice giving,decision quality,estimation accuracy,monetary rewards},
  language = {en},
  number = {3},
}
@Article{mahmoodiEqualityBiasImpairs2015,
  title = {Equality Bias Impairs Collective Decision-Making across Cultures},
  author = {Ali Mahmoodi and Dan Bang and Karsten Olsen and Yuanyuan Aimee Zhao and Zhenhao Shi and Kristina Broberg and Shervin Safavi and Shihui Han and Majid Nili Ahmadabadi and Chris D. Frith and Andreas Roepstorff and Geraint Rees and Bahador Bahrami},
  year = {2015},
  month = {mar},
  volume = {112},
  pages = {3835--3840},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1421692112},
  abstract = {We tend to think that everyone deserves an equal say in a debate. This seemingly innocuous assumption can be damaging when we make decisions together as part of a group. To make optimal decisions, group members should weight their differing opinions according to how competent they are relative to one another; whenever they differ in competence, an equal weighting is suboptimal. Here, we asked how people deal with individual differences in competence in the context of a collective perceptual decision-making task. We developed a metric for estimating how participants weight their partner's opinion relative to their own and compared this weighting to an optimal benchmark. Replicated across three countries (Denmark, Iran, and China), we show that participants assigned nearly equal weights to each other's opinions regardless of true differences in their competence\textemdash even when informed by explicit feedback about their competence gap or under monetary incentives to maximize collective accuracy. This equality bias, whereby people behave as if they are as good or as bad as their partner, is particularly costly for a group when a competence gap separates its members.},
  
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {bias,equality,joint decision-making,social cognition},
  language = {en},
  number = {12},
  pmid = {25775532},
}
@Article{harveyTakingAdviceAccepting1997,
  title = {Taking {{Advice}}: {{Accepting Help}}, {{Improving Judgment}}, and {{Sharing Responsibility}}},
  shorttitle = {Taking {{Advice}}},
  author = {Nigel Harvey and Ilan Fischer},
  year = {1997},
  month = {may},
  volume = {70},
  pages = {117--133},
  issn = {07495978},
  doi = {10.1006/obhd.1997.2697},
  
  journal = {Organizational Behavior and Human Decision Processes},
  language = {en},
  number = {2},
}
@Article{svensonAreWeAll1981,
  title = {Are We All Less Risky and More Skillful than Our Fellow Drivers?},
  author = {Ola Svenson},
  year = {1981},
  month = {feb},
  volume = {47},
  pages = {143--148},
  issn = {00016918},
  doi = {10.1016/0001-6918(81)90005-6},
  
  journal = {Acta Psychologica},
  language = {en},
  number = {2},
}
@Article{bahramiOptimallyInteractingMinds2010,
  title = {Optimally {{Interacting Minds}}},
  author = {Bahador Bahrami and Karsten Olsen and Peter E. Latham and Andreas Roepstorff and Geraint Rees and Chris D. Frith},
  year = {2010},
  volume = {329},
  pages = {1081--1085},
  issn = {0036-8075},
  abstract = {In everyday life, many people believe that two heads are better than one. Our ability to solve problems together appears to be fundamental to the current dominance and future survival of the human species. But are two heads really better than one? We addressed this question in the context of a collective low-level perceptual decision-making task. For two observers of nearly equal visual sensitivity, two heads were definitely better than one, provided they were given the opportunity to communicate freely, even in the absence of any feedback about decision outcomes. But for observers with very different visual sensitivities, two heads were actually worse than the better one. These seemingly discrepant patterns of group behavior can be explained by a model in which two heads are Bayes optimal under the assumption that individuals accurately communicate their level of confidence on every trial.},
  
  journal = {Science},
  number = {5995},
}
@Article{fetschNeuralCorrelatesReliabilitybased2012,
  title = {Neural Correlates of Reliability-Based Cue Weighting during Multisensory Integration},
  author = {Christopher R. Fetsch and Alexandre Pouget and Gregory C. DeAngelis and Dora E. Angelaki},
  year = {2012},
  volume = {15},
  pages = {146--154},
  issn = {1097-6256},
  doi = {10.1038/nn.2983},
  abstract = {Integration of multiple sensory cues is essential for precise and accurate perception and behavioral performance, yet the reliability of sensory signals can vary across modalities and viewing conditions. Human observers typically employ the optimal strategy of weighting each cue in proportion to its reliability, but the neural basis of this computation remains poorly understood. We trained monkeys to perform a heading discrimination task from visual and vestibular cues, varying cue reliability randomly. The monkeys appropriately placed greater weight on the more reliable cue, and population decoding of neural responses in the dorsal medial superior temporal area closely predicted behavioral cue weighting, including modest deviations from optimality. We found that the mathematical combination of visual and vestibular inputs by single neurons is generally consistent with recent theories of optimal probabilistic computation in neural circuits. These results provide direct evidence for a neural mechanism mediating a simple and widespread form of statistical inference.
View full text},
  copyright = {\textcopyright{} 2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  
  journal = {Nature Neuroscience},
  keywords = {Computational neuroscience,Neurophysiology,Somatosensory system},
  language = {en},
  number = {1},
}
@Article{sollJudgmentalAggregationStrategies2011,
  title = {Judgmental Aggregation Strategies Depend on Whether the Self Is Involved},
  author = {Jack B. Soll and Albert E. Mannes},
  year = {2011},
  month = {jan},
  volume = {27},
  pages = {81--102},
  issn = {01692070},
  doi = {10.1016/j.ijforecast.2010.05.003},
  abstract = {We report the results of a novel experiment that addresses two unresolved questions in the judgmental forecasting literature. First, how does combining the estimates of others differ from revising one's own estimate based on the judgment of another? The experiment found that participants often ignored advice when revising an estimate but averaged estimates when combining. This was true despite receiving identical feedback about the accuracy of past judgments. Second, why do people consistently tend to overweight their own opinions at the expense of profitable advice? We compared two prominent explanations for this, differential access to reasons and egocentric beliefs, and found that neither adequately accounts for the overweighting of the self. Finally, echoing past research, we find that averaging opinions is often advantageous, but that choosing a single judge can perform well in certain predictable situations.},
  
  journal = {International Journal of Forecasting},
  language = {en},
  number = {1},
}
@Article{yanivBenefitAdditionalOpinions2004,
  title = {The {{Benefit}} of {{Additional Opinions}}},
  author = {Ilan Yaniv},
  year = {2004},
  month = {apr},
  volume = {13},
  pages = {75--78},
  issn = {0963-7214},
  doi = {10.1111/j.0963-7214.2004.00278.x},
  abstract = {In daily decision making, people often solicit one another's opinions in the hope of improving their own judgment. According to both theory and empirical results, integrating even a few opinions is beneficial, with the accuracy gains diminishing as the bias of the judges or the correlation between their opinions increases. Decision makers using intuitive policies for integrating others' opinions rely on a variety of accuracy cues in weighting the opinions they receive. They tend to discount dissenters and to give greater weight to their own opinion than to other people's opinions.},
  
  journal = {Current Directions in Psychological Science},
  keywords = {advice,aggregating opinions,combining   information,decision-making,expertise,judgement and decision making,judgment},
  language = {en},
  number = {2},
}
@Article{yanivAdviceTakingDecision2000,
  title = {Advice {{Taking}} in {{Decision Making}}: {{Egocentric Discounting}} and {{Reputation Formation}}},
  shorttitle = {Advice {{Taking}} in {{Decision Making}}},
  author = {Ilan Yaniv and Eli Kleinberger},
  year = {2000},
  month = {nov},
  volume = {83},
  pages = {260--281},
  issn = {07495978},
  doi = {10.1006/obhd.2000.2909},
  
  journal = {Organizational Behavior and Human Decision Processes},
  language = {en},
  number = {2},
}

@Article{yanivReceivingOtherPeople2004,
  title = {Receiving Other People's Advice: {{Influence}} and Benefit},
  shorttitle = {Receiving Other People's Advice},
  author = {I. Yaniv},
  year = {2004},
  month = {jan},
  volume = {93},
  pages = {1--13},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2003.08.002},
  abstract = {Seeking advice is a basic practice in making real life decisions. Until recently, however, little attention has been given to it in either empirical studies or theories of decision making. The studies reported here investigate the influence of advice on judgment and the consequences of advice use for judgment accuracy. Respondents were asked to provide final judgments on the basis of their initial opinions and advice presented to them. The respondents' weighting policies were inferred. Analysis of the these policies show that (a) the respondents tended to place a higher weight on their own opinion than on the advisor's opinion (the self/other effect); (b) more knowledgeable individuals discounted the advice more; (c) the weight of advice decreased as its distance from the initial opinion increased; and (d) the use of advice improved accuracy significantly, though not optimally. A theoretical framework is introduced which draws in part on insights from the study of attitude change to explain the influence of advice. Finally the usefulness of advice for improving judgment accuracy is considered. (C) 2003 Elsevier Inc. All rights reserved.},
  
  journal = {Organizational Behavior and Human Decision Processes},
  keywords = {biases,confidence,determinants,forecasts,group   judgment,group decision-making,information,model,opinion change,source credibility},
  language = {English},
  number = {1},
}

@Article{yanivUsingAdviceMultiple2007,
  title = {Using Advice from Multiple Sources to Revise and Improve Judgments},
  author = {Ilan Yaniv and Maxim Milyavsky},
  year = {2007},
  month = {may},
  volume = {103},
  pages = {104--120},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2006.05.006},
  abstract = {How might people revise their opinions on the basis of multiple pieces of advice? What sort of gains could be obtained from rules for using advice? In the present studies judges first provided their initial estimates for a series of questions; next they were presented with several (2, 4, or 8) opinions from an ecological pool of advisory estimates (Experiment 1), or with artificial advice (Experiment 2); finally they provided their revised estimates. Descriptive analyses of their revision process revealed that they egocentrically trimmed the opinion sets such that opinions distant from their own were greatly discounted. Normative analyses suggest that they gained substantially from the use of advice, though not optimally, due to their self-centered utilization of the advice. The results are discussed in connection with theories of belief revision and attitude change, with an emphasis on decision-makers' strategies for coping with conflicting opinions and the appropriateness of discounting distant or dissenting opinions. Prescriptive implications for the utilization of advice are also considered. (c) 2006 Elsevier Inc. All rights reserved.},
  
  journal = {Organizational Behavior and Human Decision Processes},
  keywords = {combination,combining opinions,consistency,credibility,decision making,decision-making,determinants,discrepancy,egocentric judgment,forecasts,information search,judgment under uncertainty,opinion change,performance,utilizing advice},
  language = {English},
  number = {1},
}
@Article{jacowitzMeasuresAnchoringEstimation1995,
  title = {Measures of {{Anchoring}} in {{Estimation Tasks}}:},
  shorttitle = {Measures of {{Anchoring}} in {{Estimation Tasks}}},
  author = {Karen E. Jacowitz and Daniel Kahneman},
  year = {1995},
  month = {nov},
  publisher = {{Sage PublicationsSage CA: Thousand Oaks, CA}},
  doi = {10.1177/01461672952111004},
  abstract = {The authors describe a method for the quantitative study of anchoring effects in estimation tasks. A calibration group provides estimates of a set of uncertain ...},
  
  journal = {Personality and Social Psychology Bulletin},
  language = {en},
}
@Article{harveyEffectsJudgesForecasting2004,
  title = {Effects of Judges' Forecasting on Their Later Combination of Forecasts for the Same Outcomes},
  author = {Nigel Harvey and Clare Harries},
  year = {2004},
  month = {jul},
  volume = {20},
  pages = {391--409},
  issn = {0169-2070},
  doi = {10.1016/j.ijforecast.2003.09.012},
  abstract = {In a first experiment, we show that judges' ability to combine forecasts that they receive from more knowledgeable advisors is impaired when they have previously made their own forecasts for the same outcomes. It appears that they implicitly include their own forecasts among those that have to be combined. In a second experiment, we demonstrate that people combining forecasts put more weight on forecasts that are their own (whether or not they are labelled as such) or are labelled as their own (when they are not) than on equivalent forecasts that are neither their own nor labelled as such. We argue that the cognitive mechanisms responsible for these effects are better characterized as a type of conservatism rather than as an example of anchoring. Our results imply that people responsible for integrating forecasts from more knowledgeable advisors should not explicitly include their own forecasts among those that they combine and should consider avoiding making their own forecasts altogether.},
  
  journal = {International Journal of Forecasting},
  keywords = {Combining forecasts,Forecasting,Information integration,Judgment},
  language = {en},
  number = {3},
}
@Article{ginoWeListenAdvice2008,
  title = {Do We Listen to Advice Just Because We Paid for It? {{The}} Impact of Advice Cost on Its Use},
  shorttitle = {Do We Listen to Advice Just Because We Paid for It?},
  author = {Francesca Gino},
  year = {2008},
  month = {nov},
  volume = {107},
  pages = {234--245},
  issn = {07495978},
  doi = {10.1016/j.obhdp.2008.03.001},
  
  journal = {Organizational Behavior and Human Decision Processes},
  keywords = {accuracy,Advice taking,adviser,commitment,consumer choice,decision-making,escalation,improving judgment,Information use,Judge-Advisor System,Paid-advice effect,sunk costs,Sunk costs,system,uncertainty},
  language = {en},
  number = {2},
}
@Article{ronayneIgnoringGoodAdvice2018,
  title = {Ignoring {{Good Advice}}},
  author = {David Ronayne and Daniel Sgroi},
  year = {2018},
  abstract = {We ran an experiment where 1,503 subjects (advisees) completed tasks, and
then had the choice to submit either their own score or the score of other subjects
(advisers). The observed data are irreconcilable with rational behaviour. First,
good advice was ignored: about 25\% of the time, advisees chose to submit their
own score instead of the higher score of an adviser, reducing their payoff. Second,
when the adviser was superior in skill, good advice was ignored more often. Third,
when the adviser was relatively highly paid, subjects were less likely to make use of
them. We offer an explanation of the data focused on two behavioral forces: envy
and the sunk cost fallacy. The role of envy was complex: more envious advisees,
as measured using a dispositional envy scale, opted to follow advisers more often
in the skill-based task revealing a positive, motivational effect of envy. However, higher adviser remuneration reduced this effect, revealing a negative side of envy as a constraint on rational decision-making. Susceptibility to the sunk cost fallacy, measured using a novel scale we developed, had a negative impact on the uptake of good advice. This is consistent with the idea that subjects feel resistant to changing their answers when they put in effort to formulate them. We also present findings from a new survey of 3,096 UK voters who took part in the national referendum on EU membership, consistent with some of our experimental results. (JEL: C91, C99, D91)},
  
}
@Article{ernstHumansIntegrateVisual2002,
  title = {Humans Integrate Visual and Haptic Information in a Statistically Optimal Fashion},
  author = {Marc O. Ernst and Martin S. Banks},
  year = {2002},
  month = {jan},
  volume = {415},
  pages = {429--433},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/415429a},
  abstract = {When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visual\textendash haptic percept, for example when judging size, shape or position1,2,3, but in some circumstances the percept is clearly affected by haptics4,5,6,7. Here we propose that a general principle, which minimizes variance in the final estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation8,9,10,11,12,13,14,15 to combine the inputs. To investigate cue combination quantitatively, we first measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visual\textendash haptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation.},
  copyright = {2002 Macmillan Magazines Ltd.},
  
  journal = {Nature},
  language = {en},
  number = {6870},
}

@Article{kordingCausalInferenceMultisensory2007,
  title = {Causal {{Inference}} in {{Multisensory Perception}}},
  author = {Konrad P. K{\"o}rding and Ulrik Beierholm and Wei Ji Ma and Steven Quartz and Joshua B. Tenenbaum and Ladan Shams},
  year = {2007},
  month = {sep},
  volume = {2},
  pages = {e943},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0000943},
  abstract = {Perceptual events derive their significance to an animal from their meaning about the world, that is from the information they carry about their causes. The brain should thus be able to efficiently infer the causes underlying our sensory events. Here we use multisensory cue combination to study causal inference in perception. We formulate an ideal-observer model that infers whether two sensory cues originate from the same location and that also estimates their location(s). This model accurately predicts the nonlinear integration of cues by human subjects in two auditory-visual localization tasks. The results show that indeed humans can efficiently infer the causal structure as well as the location of causes. By combining insights from the study of causal inference with the ideal-observer approach to sensory cue combination, we show that the capacity to infer causal structure is not limited to conscious, high-level cognition; it is also performed continually and effortlessly in perception.},
  
  journal = {PLOS ONE},
  keywords = {Cognition,Human performance,Nervous system,Probability distribution,Sensory cues,Sensory perception,Vision,Visual signals},
  language = {en},
  number = {9},
}
