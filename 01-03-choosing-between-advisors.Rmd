---
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    keep_tex: false
  bookdown::word_document2: default
  bookdown::html_document2: default
documentclass: book
editor_options: 
  chunk_output_type: inline
  
bibliography: 
  - references.bib
  - bibliography/references.bib
bibliography-heading-in-pdf: Works Cited
params:
  corrections: true 
---

```{r setup 01-03, echo = F, include = F}
source('scripts_and_filters/general_setup.R')

library(BayesFactor)
library(magrittr)
library(see)
library(ggridges)
library(ggpmisc)
library(ggtext)
library(broom)
```

# Psychology of source selection {#chapter-advisor-choice}
\adjustmtc 

<!-- 
My research on advisor selection.
-->

The model of advisor evaluation described earlier (§\@ref(advisor-evaluation-without-feedback)) requires empirical support.
The model of advisor evaluation with feedback is well supported by data which indicate that, given objective feedback, people can use the feedback to learn about the trustworthiness of advisors.
The extent to which advice is taken (§\@ref(m-analysis-dv-woa)) is commonly used as a measure of a participant's trust in an advisor, on the argument that the participant seeks to maximise task performance and task performance is maximised by taking more advice from more trustworthy advisors.
\mccorrect{!TODO[Mini lit review - advisor accuracy training with feedback (Yaniv?), Niccolo and Nick's feedback stuff]}.
Overall, this means that people prefer more accurate advice over less accurate advice.

When objective feedback is unavailable, people can still demonstrate a greater dependence upon advice from more as opposed to less accurate advisors.
\mccorrect{!TODO[Mini lit review, Niccolo's stuff, maybe prior stuff - check Niccolo's thesis for references]}.
This is a consequence of agreement: where the base probability of being correct is greater than chance, the independent estimates of people who are more accurate will agree more often (leading to 100% agreement on the correct answer for two independent decision-makers of perfect accuracy).
In the absence of feedback, therefore, agreement can be used as a proxy for accuracy, as formalised in the model.

The role of agreement is demonstrated clearly in experiments where the objective accuracy of advisors is balanced, but the agreement rates of the advisors is varied.
\mccorrect{!TODO[cite Niccolo CITE]}.
Pescetelli and Yeung demonstrated that advice is more influential from advisors who tend to agree with a participant more frequently when objective feedback is not provided.
This is despite the fact that advice is more influential when it disagrees with the participant's initial estimate.
^[This is partly due to the nature of the judge-advisor system: there is always room for disagreement to be more extreme than agreement, because agreement is lower-bounded by the participant's initial estimate.] 
These data suggest that people may be using agreement as a proxy for accuracy, although they may simply prefer agreement over disagreement when there is no accuracy cost to be paid.
I report the results of an experiment in which an agreeing advisor was compared with an accurate advisor under conditions of feedback or no feedback.
Results indicated that, as predicted by the models, participants preferred the accurate advisor when feedback was provided and the agreeing advisor when feedback was withheld.

Pescetelli and Yeung developed a more sophisticated model of advisor evaluation in which the increase in trust gained when an advisor agreed with the decision-maker was contingent upon the confidence of the decision-maker's initial estimate (§\@ref(confidence-weighted-agreement)).
Intuitively, if I am highly certain that I am correct on a given question, an advisor who disagrees with me is likely to be incorrect, whereas one who agrees with me is likely to be correct.
Provided confidence is indicative of the objective probability of being correct, as confidence in the initial decision increases it more closely approximates objective feedback for the purposes of evaluating advice.
\mccorrect{!TODO[detailed account of Niccolo's evidence for the confidence-weighted model]}.
I report the results of experiments designed to extend Pescetelli and Yeung's results to the domain of advisor influence, using two different decision-making tasks.


<!-- Presentation of the experiments (may want different subsections for each experiment and an extra one for the general discussion).
-->

<!-- The results for each experiment are included in their own files because they're just too damn long for hackMD.io to handle -->
```{r, child=c('_acc.Rmd', '_agr.Rmd',  '_ava.Rmd', '_cca.Rmd'), results='asis'}
```

## General discussion

The patterns observed for advice taking are also evident in advisor selection.
Modelling work \mccorrect{!TODO[lots of citations for this]} indicates that biased source selection can dramatically reshape communication networks and create echo chamber effects where accurate but unpalatable information is ignored.
Empirical research on source selection behaviour has found relatively little indication that people behave this way in the real world \mccorrect{!TODO[source selection experiments citations]}, but here we are at least able to demonstrate in principle a psychological mechanism which could drive biased source selection.
Furthermore, the mechanisms which produce biased source selection are rational and appropriate given the information available to participants.

### Advisor choice results

The preferences for advisors were broadly consistent with the pattern expected from previous work on advisor influence.
Where objective feedback could be used to calculate advisor performance, participants showed a systematic preference for picking the advisor who would provide the most accurate advice.
Where objective feedback was unavailable, participants only showed a clear preference for High agreement advisors over Low agreement advisors (although in the Dates task there was also a preference for High accuracy over Low accuracy advisors).
These results are consistent with an account of advisor trust updating which uses agreement as a proxy for advisor accuracy when more reliable information is not available.

### Differences between tasks

The studies here explore the different manipulations of advice profile using two different tasks: a Dots task with a perceptual decision and a Dates task using an estimation decision.
These two tasks have consistent results, but there are nevertheless identifiable differences between the tasks.
Most notably, although advisor choice distributions in both tasks are roughly normally distributed, those in the Dots task results are sharper.
This sharpness may be a result of many participants selecting advisors at approximately equal rates.
If participants become bored or fatigued by the experiment they may disengage and select advisors in a random manner.
\mccorrect{!TODO[Did we restore advisor agreement/accuracy/etc to a baseline during Test phase? If so participants might detect a return to baseline from their favourite advisor and explore away.]}

Where manipulations are effective in the Dots task (§\@ref(ac-ava-dots)) they change the direction of preferences: a good many participants continue to pick advisors at approximately equal rates, but preferences in those who do express a preference systematically favour one particular advisor.
Systematic differences in the Dates task are signified by distributions in which the modal preference moves to an extreme preference for the relevant advisor while the tails of the distribution continue to cover the whole range.
These differences are likely a consequence of the difference in the number of Choice trials in each Task: because the Dates task only has around 10 Choice trials it is relatively common for participants to select a single preferred advisor repeatedly, while participants in the Dots task may become tired of seeing advice from the same advisor over the \mccorrect{!TODO[how many Choice trials in Dots?]} Choice trials in the Dots task, increasing the novelty value of advice from the non-preferred advisor and thus reducing the apparent strength of preference.
\mccorrect{Long sentence: revise}

The only case in which results between the No feedback condition of the Dates task and the Dots task were in conflict was High vs Low accuracy advisors. 
Participants in the Dots task had a systematic preference for the High accuracy advisor (§\@ref(ac-acc-dates)).
These differences are likely caused by the greater accuracy participants display in the Dots task making the experienced agreement profiles of the advisors more distinct.
This explanation is wholly consistent with an account of advisor trust which uses agreement as a proxy for accuracy when better information is unavailable.
This explanation entails a prediction that longer-term experience with the High accuracy advisor should eventually engender a systematic preference for that advisor, provided participants' guesses are more accurate than chance.

### Variability between participants

As noted above, participants displayed a range of preferences. 
Most participants in most conditions in most studies demonstrated fairly balanced picking behaviour; perhaps motivated by a sense of fairness or novelty, or perhaps as a result of random selection. \mccorrect{!TODO[We could take a quick look at whether participants tend to always pick the advisor in the first/second position, and how that correlates with preference strength. Could relate to choice-induced bias for advisor position: zajkowskiCrossDomainEffectsChoiceInduced2021]}
Where effects appear in the data, they show up as a fat tail on a skewed distribution: a sizeable minority select a given advisor on most trials, and almost no one selects the other advisor on most of the trials.

This heterogeneity is seldom measured in population models of influence dynamics. 
In the [following chapter](#chapter-network-effects), we explore the effects of including this kind of heterogeneity in agent-based models of advice giving.

### Strengths

### Limitations

### Conclusion
